{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "한국어_LDA_example.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMvOSLVxPfbl2Rc6EmFpmxe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hohohohyun/django/blob/master/%ED%95%9C%EA%B5%AD%EC%96%B4_LDA_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXXN1MGv8t0J",
        "outputId": "8b1b6ec2-78de-4509-89b3-0d0278a4858c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRl0J0Osi-fb"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from konlpy.tag import Kkma, Okt"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8BeCwCri1V9",
        "outputId": "dcf6b59e-d776-43d5-8937-94a1bab37334",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.7.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.9.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT6x_kQ97_mk"
      },
      "source": [
        "네이버영화 리뷰 데이터를 이용한 토픽 모델링 예시 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdhIKxa1cL6N"
      },
      "source": [
        "mr = pd.read_csv('/content/drive/My Drive/movie_review.txt', sep='\\t', quoting=3)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W39ydgac9tKd",
        "outputId": "a7ca7afe-7da6-49d9-c4b3-d4cb5175c67c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "mr"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6270596</td>\n",
              "      <td>굳 ㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9274899</td>\n",
              "      <td>GDNTOPCLASSINTHECLUB</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8544678</td>\n",
              "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6825595</td>\n",
              "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6723715</td>\n",
              "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>4608761</td>\n",
              "      <td>오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>5308387</td>\n",
              "      <td>의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>9072549</td>\n",
              "      <td>그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>5802125</td>\n",
              "      <td>절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>6070594</td>\n",
              "      <td>마무리는 또 왜이래</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id                                           document  label\n",
              "0      6270596                                                굳 ㅋ      1\n",
              "1      9274899                               GDNTOPCLASSINTHECLUB      0\n",
              "2      8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
              "3      6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
              "4      6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0\n",
              "...        ...                                                ...    ...\n",
              "49995  4608761          오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함      1\n",
              "49996  5308387       의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO      0\n",
              "49997  9072549                 그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다      0\n",
              "49998  5802125     절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네      0\n",
              "49999  6070594                                         마무리는 또 왜이래      0\n",
              "\n",
              "[50000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCSyVa2bfy1o"
      },
      "source": [
        "## 문장 데이터만 사용\n",
        "ex_data = mr['document']"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aki9gLpE5jPe",
        "outputId": "31962df5-b758-4c82-e20b-1d458ddc5611",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#빈 문자열 NAN 값으로 바꾸기\n",
        "clean_Data = ex_data.replace({'': np.nan})\n",
        "clean_Data = clean_Data.replace(r'^\\s*$', None, regex=True)\n",
        "\n",
        "#한글이 아닌 단어 공백으로 처리\n",
        "clean_Data = clean_Data.replace('^ ㄱ-힣', '', regex=True)\n",
        "\n",
        "#NAN 이 있는 행은 삭제\n",
        "clean_Data.dropna(how='any', inplace=True)\n",
        "\n",
        "#행을 제거하면서 망가진 인덱스 초기화\n",
        "clean_Data = clean_Data.reset_index (drop = True)\n",
        "\n",
        "#데이터 프레임에 null 값이 있는지 확인\n",
        "print(clean_Data.isnull().values.any()) "
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj3BKdqOJPUs"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72lTIrzhW72V"
      },
      "source": [
        "####형태소 분석기 꼬꼬마 사용\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA1UW6paZ_M9"
      },
      "source": [
        "## 불용어 설정은 띄어쓰기로 구분하여 설정하시면 됩니다\n",
        "## 기존에 설정되어있는 불용어 사전을 사용하려다가 토픽분석을 실시하면서 나오는 불용어들을 추가하면서 만들었습니다. 기존에 존재하는 한국어 불용어사전을 사용하셔도 됩니다.\n",
        "## 한국어 불용어 사전 링크 https://www.ranks.nl/stopwords/korean\n",
        "\n",
        "stop_words = '''ㅋㅋ 너무 진짜 정말 ㅎㅎ 같은 그냥 ㅋㅋㅋ 진짜 역시 그럼 근데 이거 하세요 ㅡㅡ ㅋㅋㅋㅋ ㅠㅠ 에서 한테 으로 하고 인데 원래 인가 이나 ㅉㅉ 하는 이다 하냐 해도 이랑 했는데 건가 합시다 하나 에는 하네 보고 보다 입니다 인지 이지 하면\n",
        "이건 ㅋㅋㅋㅋㅋ 되는 이네 하지 이고 40 봤습니다 10 하다 이건 봤는데 까지 던데 ㄴ데 내가 우리'''\n",
        "\n",
        "stop_words=stop_words.split(' ') ## 띄어쓰기로 구분된 불용어 리스트로 재설정(하나씩 따옴표 써가면서 만들기가 번거로워서 선택한 방법입니다.)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl6Ucht7xVzD"
      },
      "source": [
        "from konlpy.tag import Kkma  \n",
        "\n",
        "## Kkma를 이용한 한국어 토큰화 과정\n",
        "\n",
        "def tokenizing(tag, data):\n",
        "  ## 선택한 품사tag 방식에 따른 토큰화 과정\n",
        "  tag_=tag()\n",
        "  tk_data = []\n",
        "  for tkns in data:  \n",
        "    tk_data.append(tag_.morphs(tkns))\n",
        "\n",
        "  ## 불용어 제거단계  \n",
        "  result = [] \n",
        "  for tkns in tk_data:\n",
        "    tmp = []\n",
        "    for w in tkns: \n",
        "      if w not in stop_words: \n",
        "          tmp.append(w) \n",
        "    result.append(tmp)\n",
        "  \n",
        "  return result\n",
        "\n",
        "result = tokenizing(Kkma, clean_Data[-3000:]) ## 3000개로 예시"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA85ybg9_mQC"
      },
      "source": [
        "명사만 사용한 방법과 모든 단어를 다 사용한 방법을 둘다 사용하기 위해서 함수를 하나 더 설정했습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aLFScD3arTm"
      },
      "source": [
        "## TF-IDF 행렬을 만들기 위하여 다시 띄어쓰기로 구분하여 문장형식으로 재구성\n",
        "def corpus(tokens):\n",
        "  corp = []\n",
        "  for sent in tokens:\n",
        "    tmp = \" \".join(sent)\n",
        "    corp.append(tmp)\n",
        "\n",
        "  return corp\n",
        "\n",
        "train_corp = corpus(result)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DND-qAX5knzp"
      },
      "source": [
        "## 키워드 분석을 위하여 명사들만 추출\n",
        "def n_corpus(corpus):\n",
        "  corp = []\n",
        "  for sent in corpus:\n",
        "    tmp = \" \".join(kkma.nouns(sent)) # Kkma에서 제공하는 품사 태깅에서 명사들만 추출하여 문장을 재구성한다.\n",
        "    corp.append(tmp)\n",
        "  return corp\n",
        "\n",
        "n_corp = n_corpus(train_corp)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy6PF8pNYEKC"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "## 명사 뿐이 아닌 다른 단어도 사용하기 위해서는 n_corp 대신 train_corp 사용\n",
        "tfidfv = TfidfVectorizer().fit(n_corp)\n",
        "tfidf_km = tfidfv.transform(n_corp).toarray()\n",
        "# print(tfidfv.vocabulary_) ## 구성단어 사전"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exvZPApRZBZs"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda_model=LatentDirichletAllocation(n_components=5,learning_method='online',random_state=0,max_iter=1)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZVsBtOQZzXt"
      },
      "source": [
        "lda_top=lda_model.fit_transform(tfidf_km)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tWIImxaZ2yl",
        "outputId": "4ce30553-3471-481c-9759-3c2cbfd0a5e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "terms = tfidfv.get_feature_names() ## TF-IDF vectorizer 안에 있는 단어들\n",
        "\n",
        "def get_topics(components, feature_names, n=10): ## n : 토픽 별로 나타나는 단어의 갯수\n",
        "    for idx, topic in enumerate(components):\n",
        "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(2)) for i in topic.argsort()[:-n - 1:-1]])\n",
        "\n",
        "## 결과 도출(Kkma)\n",
        "get_topics(lda_model.components_,terms)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 1: [('재미', 15.33), ('생각', 14.69), ('시간', 14.21), ('영화', 12.43), ('사랑', 10.37), ('기분', 9.72), ('추천', 8.12), ('기억', 6.63), ('노래', 6.43), ('다가', 5.48)]\n",
            "Topic 2: [('영화', 116.85), ('최고', 37.03), ('연기', 33.22), ('미있', 29.14), ('재미있', 29.12), ('드라마', 26.13), ('사람', 23.82), ('감독', 22.77), ('내용', 22.69), ('배우', 21.58)]\n",
            "Topic 3: [('재밌', 69.07), ('영화', 26.77), ('평점', 17.32), ('기대', 15.86), ('감동', 12.94), ('실망', 11.08), ('감동적', 9.51), ('세상', 8.78), ('신선', 8.1), ('가족', 7.92)]\n",
            "Topic 4: [('버리', 10.1), ('영화', 8.77), ('이름', 8.36), ('공포', 7.32), ('장르', 7.28), ('걸작', 6.68), ('만화', 6.28), ('지리', 6.25), ('강추', 6.05), ('전쟁', 5.92)]\n",
            "Topic 5: [('미없', 27.14), ('재미없', 26.87), ('이것', 23.98), ('영화', 20.03), ('가슴', 11.45), ('이상', 10.54), ('수준', 10.4), ('름답', 7.53), ('짜증', 7.46), ('평가', 6.43)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXltgP5r6TMz"
      },
      "source": [
        "#### 형태소 분석기 Okt(Open Korea Text) 사용\n",
        " - 위와 동일하고 형태소 분석기만 Okt를 사용하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2B8WOw-JUq6"
      },
      "source": [
        "from konlpy.tag import Okt  \n",
        "\n",
        "result_o = tokenizing(Okt, clean_Data[-3000:]) ## 3000개로 예시"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFmNvYOg1f9u"
      },
      "source": [
        "train_corp_o = corpus(result_o)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9O85Xa51f9v"
      },
      "source": [
        "n_corp_o = n_corpus(train_corp_o)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkFY6l5t1f9x"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidfv = TfidfVectorizer().fit(n_corp_o)\n",
        "tfidf_ = tfidfv.transform(n_corp_o).toarray()\n",
        "# print(tfidfv.vocabulary_[:100])"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnrEuLOO1f9z"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda_model=LatentDirichletAllocation(n_components=5,learning_method='online',random_state=0,max_iter=1)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDLAkULL1f92"
      },
      "source": [
        "lda_top=lda_model.fit_transform(tfidf_)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qccKJ15C1f93",
        "outputId": "4348f12e-4e65-46b0-ff30-edcc6fa2d489",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "terms = tfidfv.get_feature_names() ## TF-IDF vectorizer 안에 있는 단어들\n",
        "\n",
        "def get_topics(components, feature_names, n=10): ## n : 토픽 별로 나타나는 단어의 갯수\n",
        "    for idx, topic in enumerate(components):\n",
        "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(2)) for i in topic.argsort()[:-n - 1:-1]])\n",
        "\n",
        "## 결과 도출(Okt)\n",
        "get_top ics(lda_model.components_,terms)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 1: [('영화', 22.54), ('최악', 19.76), ('재밋', 13.81), ('인생', 12.28), ('주인공', 10.56), ('사람', 10.21), ('진심', 10.11), ('아이', 9.25), ('나름', 8.61), ('무엇', 7.91)]\n",
            "Topic 2: [('재미', 31.58), ('드라마', 20.84), ('완전', 16.89), ('흥미', 10.21), ('명작', 9.36), ('현실', 7.02), ('마무리', 6.75), ('모습', 6.54), ('영화', 6.24), ('내용', 5.56)]\n",
            "Topic 3: [('최고', 43.51), ('영화', 43.37), ('평점', 33.56), ('생각', 30.63), ('쓰레기', 20.4), ('이야기', 19.59), ('감독', 17.83), ('사랑', 14.69), ('이상', 12.86), ('작품', 12.27)]\n",
            "Topic 4: [('감동', 37.87), ('영화', 35.92), ('연기', 26.21), ('스토리', 23.15), ('배우', 17.6), ('처음', 15.51), ('내용', 15.12), ('기대', 14.97), ('정도', 14.95), ('가슴', 13.69)]\n",
            "Topic 5: [('영화', 84.16), ('시간', 25.66), ('코미디', 13.48), ('매력', 10.88), ('후회', 9.88), ('음악', 9.62), ('가족', 8.92), ('추천', 8.49), ('수준', 8.27), ('장르', 8.15)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}